#!/usr/bin/env python3
"""
Setup script for Aven Support Scraper
"""
import os
import sys
import subprocess
from pathlib import Path

def print_banner():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                Aven Support Scraper Setup                   â•‘
â•‘              Powered by Exa.ai Neural Search                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

def install_dependencies():
    """Install required Python packages"""
    print("ğŸ“¦ Installing dependencies...")
    
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
        print("âœ… Dependencies installed successfully!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Failed to install dependencies: {e}")
        return False

def create_env_file():
    """Create .env file from template"""
    print("\nğŸ”§ Setting up configuration...")
    
    env_file = Path(".env")
    template_file = Path("config.template")
    
    if env_file.exists():
        response = input("âš ï¸  .env file already exists. Overwrite? (y/N): ")
        if response.lower() != 'y':
            print("Keeping existing .env file.")
            return True
    
    if not template_file.exists():
        print("âŒ config.template not found!")
        return False
    
    # Copy template to .env
    with open(template_file, 'r') as src, open(env_file, 'w') as dst:
        dst.write(src.read())
    
    print("âœ… Created .env file from template")
    
    # Get API key from user
    api_key = input("\nğŸ”‘ Please enter your Exa.ai API key (or press Enter to skip): ").strip()
    
    if api_key:
        # Update .env file with API key
        with open(env_file, 'r') as f:
            content = f.read()
        
        content = content.replace('your_exa_api_key_here', api_key)
        
        with open(env_file, 'w') as f:
            f.write(content)
        
        print("âœ… API key saved to .env file")
    else:
        print("âš ï¸  You can add your API key later by editing the .env file")
    
    return True

def create_directories():
    """Create necessary directories"""
    print("\nğŸ“ Creating directories...")
    
    directories = [
        "scraped_data",
        "scraped_data/content_chunks",
        "scraped_data/by_content_type"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… Created: {directory}/")
    
    return True

def verify_installation():
    """Verify that everything is installed correctly"""
    print("\nğŸ” Verifying installation...")
    
    try:
        # Test imports
        import exa_py
        print("âœ… exa-py package available")
        
        import pandas as pd
        print("âœ… pandas package available")
        
        import beautifulsoup4
        print("âœ… beautifulsoup4 package available")
        
        # Test configuration
        from config import config
        print("âœ… Configuration module loaded")
        
        # Test content processor
        from content_processor import ContentProcessor
        print("âœ… Content processor available")
        
        # Test main scraper
        from aven_scraper import AvenScraper
        print("âœ… Main scraper available")
        
        print("\nğŸ‰ Installation verified successfully!")
        return True
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Verification failed: {e}")
        return False

def show_next_steps():
    """Show user what to do next"""
    print("""
ğŸš€ Setup Complete! Next Steps:

1. Configure your API key (if not done already):
   â€¢ Edit .env file and add your Exa.ai API key
   â€¢ Get a free API key at: https://dashboard.exa.ai/

2. Test the installation:
   python run_scraper.py validate

3. Run your first scrape:
   python run_scraper.py scrape --max-pages 10

4. View all available options:
   python run_scraper.py --help

ğŸ“ Output will be saved to: ./scraped_data/

Happy scraping! ğŸ•·ï¸
""")

def main():
    """Main setup function"""
    print_banner()
    
    success = True
    
    # Install dependencies
    if not install_dependencies():
        success = False
    
    # Create configuration
    if success and not create_env_file():
        success = False
    
    # Create directories
    if success and not create_directories():
        success = False
    
    # Verify installation
    if success and not verify_installation():
        success = False
    
    if success:
        show_next_steps()
        return 0
    else:
        print("\nâŒ Setup encountered errors. Please check the output above.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 