# AI Customer Support Server Configuration
# Copy this file to .env and fill in your actual values

# ================================
# SERVER CONFIGURATION
# ================================
PORT=5000
NODE_ENV=development

# CORS Configuration (comma-separated origins)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# ================================
# PINECONE CONFIGURATION
# ================================
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here

# ================================
# OPENAI CONFIGURATION
# ================================
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
MAX_TOKENS=1000
TEMPERATURE=0.7

# ================================
# OPTIONAL: EXA SEARCH
# ================================
EXA_API_KEY=your_exa_api_key_here

# ================================
# RAG PIPELINE SETTINGS
# ================================
# Number of relevant chunks to retrieve from Pinecone
TOP_K_RESULTS=5

# Maximum message length in characters
MAX_MESSAGE_LENGTH=10000

# ================================
# LOGGING AND MONITORING
# ================================
# Set to 'debug' for verbose logging
LOG_LEVEL=info

# ================================
# SECURITY SETTINGS
# ================================
# Add any additional security configurations here
# JWT_SECRET=your_jwt_secret_here (for future authentication)
# RATE_LIMIT_WINDOW=15 (minutes)
# RATE_LIMIT_MAX=100 (requests per window) 